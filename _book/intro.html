<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>outlier-detection.utf8.md</title>
  <meta name="description" content="This article is concerned with outlier detection using regression in R.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="outlier-detection.utf8.md" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This article is concerned with outlier detection using regression in R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="outlier-detection.utf8.md" />
  
  <meta name="twitter:description" content="This article is concerned with outlier detection using regression in R." />
  

<meta name="author" content="Samuel Lippl">


<meta name="date" content="2018-09-30">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="methodology.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Outlier Detection using Regression</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction: neurons, models and outliers</a></li>
<li class="chapter" data-level="2" data-path="methodology.html"><a href="methodology.html"><i class="fa fa-check"></i><b>2</b> Methodology</a><ul>
<li class="chapter" data-level="2.1" data-path="methodology.html"><a href="methodology.html#a-nested-account-of-outlier-detection"><i class="fa fa-check"></i><b>2.1</b> A nested account of outlier detection</a></li>
<li class="chapter" data-level="2.2" data-path="methodology.html"><a href="methodology.html#context-probabilistic-and-cluster-analysis-for-outlier-detection"><i class="fa fa-check"></i><b>2.2</b> Context: Probabilistic and cluster analysis for outlier detection</a></li>
<li class="chapter" data-level="2.3" data-path="methodology.html"><a href="methodology.html#z-scoring-a-heuristic-for-normalization-of-outlier-scores"><i class="fa fa-check"></i><b>2.3</b> Z-Scoring: A heuristic for normalization of outlier scores</a></li>
<li class="chapter" data-level="2.4" data-path="methodology.html"><a href="methodology.html#evaluation-of-outlier-detection-algorithms"><i class="fa fa-check"></i><b>2.4</b> Evaluation of outlier detection algorithms</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>3</b> Linear Outlier Detection</a><ul>
<li class="chapter" data-level="3.1" data-path="linear.html"><a href="linear.html#linear-model"><i class="fa fa-check"></i><b>3.1</b> Linear Models</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear.html"><a href="linear.html#motivation"><i class="fa fa-check"></i><b>3.1.1</b> Motivation</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear.html"><a href="linear.html#definition-and-implementation-in-r"><i class="fa fa-check"></i><b>3.1.2</b> Definition and implementation in R</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear.html"><a href="linear.html#example-application"><i class="fa fa-check"></i><b>3.1.3</b> Example application</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear.html"><a href="linear.html#data-compression-and-correction"><i class="fa fa-check"></i><b>3.1.4</b> Data compression and correction</a></li>
<li class="chapter" data-level="3.1.5" data-path="linear.html"><a href="linear.html#discussion"><i class="fa fa-check"></i><b>3.1.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear.html"><a href="linear.html#linear-pca"><i class="fa fa-check"></i><b>3.2</b> Principal Component Analysis</a><ul>
<li class="chapter" data-level="3.2.1" data-path="linear.html"><a href="linear.html#motivation-1"><i class="fa fa-check"></i><b>3.2.1</b> Motivation</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear.html"><a href="linear.html#definition"><i class="fa fa-check"></i><b>3.2.2</b> Definition</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear.html"><a href="linear.html#example-application-1"><i class="fa fa-check"></i><b>3.2.3</b> Example application</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear.html"><a href="linear.html#data-compression-and-correction-1"><i class="fa fa-check"></i><b>3.2.4</b> Data compression and correction</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear.html"><a href="linear.html#discussion-1"><i class="fa fa-check"></i><b>3.2.5</b> Discussion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="nonlinear-extensions.html"><a href="nonlinear-extensions.html"><i class="fa fa-check"></i><b>4</b> Nonlinear extensions</a><ul>
<li class="chapter" data-level="4.1" data-path="nonlinear-extensions.html"><a href="nonlinear-extensions.html#kernel-pca"><i class="fa fa-check"></i><b>4.1</b> Kernel PCA</a><ul>
<li class="chapter" data-level="4.1.1" data-path="nonlinear-extensions.html"><a href="nonlinear-extensions.html#motivation-2"><i class="fa fa-check"></i><b>4.1.1</b> Motivation</a></li>
<li class="chapter" data-level="4.1.2" data-path="nonlinear-extensions.html"><a href="nonlinear-extensions.html#definition-1"><i class="fa fa-check"></i><b>4.1.2</b> Definition</a></li>
<li class="chapter" data-level="4.1.3" data-path="nonlinear-extensions.html"><a href="nonlinear-extensions.html#example-application-2"><i class="fa fa-check"></i><b>4.1.3</b> Example application</a></li>
<li class="chapter" data-level="4.1.4" data-path="nonlinear-extensions.html"><a href="nonlinear-extensions.html#discussion-2"><i class="fa fa-check"></i><b>4.1.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="nonlinear-extensions.html"><a href="nonlinear-extensions.html#neural-networks"><i class="fa fa-check"></i><b>4.2</b> Neural networks</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>5</b> Summary</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction: neurons, models and outliers</h1>
<p>In the late 1990s, neuroscientists faced a curious problem. They investigated a set of neurons which started to fire when a bar with a certain orientation appeared within their receptive field, i. e. the visual area these neurons were concerned with. However, when this bar extended their receptive field, the firing stopped. This behaviour is called <em>endstopping</em>.</p>
<div class="figure"><span id="fig:endstopping"></span>
<img src="outlier-detection_files/figure-html/endstopping-1.gif" alt="Illustration of endstopping: The shaded rectangle shows the receptive field of the neuron. The black rectangle represents the bar. If the receptive field is grey, the neuron does not fire, if it is orange, the neuron fires." width="100%" />
<p class="caption">
Figure 1.1: Illustration of endstopping: The shaded rectangle shows the receptive field of the neuron. The black rectangle represents the bar. If the receptive field is grey, the neuron does not fire, if it is orange, the neuron fires.
</p>
</div>

<p>Different functions of these endstopped neurons had been postulated. Studies had suggested a role for these cells in detecting curvature, line terminations, occlusion, perceptual grouping and illusory contours. <span class="citation">(Rao and Ballard <a href="#ref-Rao1999">1999</a>)</span> Rao and Ballard’s study presented an alternative explanation for this effect. Their analysis suggested that higher-level neurons whose receptive field resembled the entire area in figure <a href="intro.html#fig:endstopping">1.1</a> predicted the lower-level input. Feedback connections transmitted the error of the transmission. According to Rao and Ballard, the endstopped neurons had the function of error feedback.</p>
<p>They demonstrated this by fitting a hierarchical model with three layers on image patches extracted from five natural photos such that the higher-level layers optimally predicted the lower-level layers. The feedback nodes encoding the difference between the values in the second layer and the values that had been predicted by the third layer exhibited endstopping effects. <span class="citation">(Rao and Ballard <a href="#ref-Rao1999">1999</a>)</span></p>
<p>The explanation for neuronal endstopping therefore consists of two parts: firstly, the structure of neuronal networks allow for association of neighbouring pixels which is necessary to detect bars. Secondly, short bars are less usual than longer bars<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. This is the reason why the higher-level neurons predict a longer bar in these cases and receive a higher error feedback signal. Short bars are therefore <em>outliers</em>. Endstopped neurons thus provide a natural example for outlier detection.</p>
<p>Since these investigation, predictive coding, the hypothesis that higher-level neuronal layers attempt to predict lower-level layers, has become popular with respect to different areas of the brain <span class="citation">(Friston <a href="#ref-Friston2005">2005</a>)</span>. Intuitively, this makes sense: if the received input represents usual patterns the information of the higher-level neurons suffices so that lower-level correction is only required if something unusual happens. This allows the brain to build a model of reality as such a model cannot account for all irregularities and retain its descriptive power. Consider, for instance, a chess game where the player attempts to predict his opponent’s actions. It is impossible to consider all possible moves. Instead, the player has to restrict himself to the most probable ones. If the next move has been considered by the player, his opponent behaves in the usual way and the player can rest assured. In contrast, if the player has not considered the next move, he may be alerted. Unusual behavior therefore merits special attention, in particular, if it is impossible to model all paths of behavior.</p>
<p>The statistical implementation of this strategy is given by outlier detection. The examples are manifold:</p>
<ul>
<li>It is impossible to model all possible methods to commit credit card fraud. Instead, we simply try to detect unusual behavior.</li>
<li>There are many different reasons why data points may deviate from the assumptions of the classical linear model but many of these deviations are observable by looking at different kinds of residual errors.</li>
<li>There are many different reasons why a sensor can be corrupted and not all of them can be considered. However, many of them manifest themselves in unusual patterns.</li>
</ul>
<p><em>Outliers</em> can now be defined as those data points that are <em>dissimilar from the other data points</em> <span class="citation">(see Aggarwal <a href="#ref-Aggarwal2017">2017</a>)</span>. The particular outlier detection methods defines what it means for data points to be similar to each other. For instance, with respect to the endstopping neurons, image patches are similar if they can be characterized by the same neuronal model.</p>
<p>This report focuses on methods that generate predictions and assess them in order to judge how <em>usual</em> a certain data point is. Its structure is based on chapter 3 of Aggarwal’s <em>Outlier Analysis</em> <span class="citation">(<a href="#ref-Aggarwal2017">2017</a>)</span>. Two alternative popular approaches are probabilistic modeling <span class="citation">(Aggarwal <a href="#ref-Aggarwal2017">2017</a>, ch. 2)</span> and clustering <span class="citation">(Aggarwal <a href="#ref-Aggarwal2017">2017</a>, ch. 4)</span>. Note that the distinction is not well-defined and there are many methods that can be attributed to different fields (see <a href="#methods">chapter 2</a>).</p>
<p><a href="#methods">Chapter 2</a> presents a general methodology to assess outlier scores and introduces the <em>Z-plot</em> as a visualization of outlier scores..</p>
<p>Subsequently, <a href="linear.html#linear">chapter 3</a> introduces outlier detection using linear models and principal component analysis. All these methods are limited by the fact that they can only model linear relationships. This disadvantage is adressed in <a href="#nonlinear">chapter 4</a> where nonlinear extensions of these methods are introduced. Specifically, the kernel trick is introduced yielding kernel principal component analysis. Finally, more complex regressions, in particular neural networks, are introduced. Methodological instructions consist of the following parts:</p>
<ul>
<li><strong>Motivation</strong> and <strong>intuition</strong>: What does it mean for a data point to be usual? What hyperparameters need to be adjusted and how do they affect whether data points are usual?</li>
<li><strong>Implementation</strong> in R</li>
<li>Example <strong>application</strong>: a two-dimensional outlier analysis using different generated datasets should provide an intuition for advantages and disadvantages of every method as it is visually easy to assess</li>
<li>Applications in <strong>compression</strong> and data <strong>correction</strong>, two related fields to outlier detection</li>
<li><strong>Pro</strong> and <strong>Contra</strong></li>
</ul>

</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Rao1999">
<p>Rao, Rajesh P N, and Dana H Ballard. 1999. “Predictive Coding in the Visual Cortex: a Functional Interpretation of Some Extra- classical Receptive-field Effects.” <em>Nature Neuroscience</em> 2 (1). <a href="https://doi.org/10.1038/4580" class="uri">https://doi.org/10.1038/4580</a>.</p>
</div>
<div id="ref-Friston2005">
<p>Friston, Karl. 2005. “A theory of cortical responses.” <em>Philosophical Transactions of the Royal Society B</em> 360:815–36. <a href="https://doi.org/10.1098/rstb.2005.1622" class="uri">https://doi.org/10.1098/rstb.2005.1622</a>.</p>
</div>
<div id="ref-Aggarwal2017">
<p>Aggarwal, Charu C. 2017. <em>Outlier Analysis</em>. Springer Publishing Company, Incorporated.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Rao and Ballard demonstrated this by another investigation <span class="citation">(Rao and Ballard <a href="#ref-Rao1999">1999</a>)</span>.<a href="intro.html#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="methodology.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["outlier-detection.pdf", "outlier-detection.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
